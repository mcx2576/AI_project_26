{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "import csv, json\n",
    "\n",
    "def download_experiment(experiment):\n",
    "    GEOparse.get_GEO(geo=experiment, destdir=\"data/\")\n",
    "\n",
    "def process_experiment(experiment):\n",
    "    return GEOparse.get_GEO(filepath=\"data/\" + experiment + \"_family.soft.gz\")\n",
    "\n",
    "def aggregate_samples(experiment, download=True):  \n",
    "    '''\n",
    "    Wrapper function to download and process a given experiment ID,\n",
    "    aggregate the samples and write them to a csv file as a matrix.\n",
    "    '''\n",
    "    if download:\n",
    "        download_experiment(experiment)\n",
    "    print('process experiment...')\n",
    "    gse = process_experiment(experiment)\n",
    "    aggregated_samples = pd.DataFrame()\n",
    "    genes = pd.DataFrame()\n",
    "    print('aggregating samples...')\n",
    "    for sample in gse.gsms:\n",
    "        name = gse.gsms[sample].metadata['title'][0]\n",
    "        sample_df = gse.gsms[sample].table\n",
    "        sample_df.columns = ['gene', name]\n",
    "        genes = sample_df['gene']\n",
    "        aggregated_samples = pd.concat([aggregated_samples, sample_df[name]], axis=1)    \n",
    "    aggregated_samples = pd.concat([genes, aggregated_samples], axis=1)\n",
    "    aggregated_samples.to_csv('data/' + experiment + '_full_matrix.csv') \n",
    "    print('aggregated samples written to csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def distribution_parameters(gene, genes):\n",
    "    gene_differences = np.array([g-gene for g in genes])\n",
    "    covariance = np.cov(gene_differences, rowvar=False)\n",
    "    mean = np.mean(gene_differences, axis=0)\n",
    "    return mean, covariance\n",
    "\n",
    "def score_multivariate(x, mean, covariance):\n",
    "    return 1-multivariate_normal.pdf(x, mean=mean, cov=covariance)\n",
    "\n",
    "def score_cosine(x, y):\n",
    "    return (np.dot(x, np.transpose(y))/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "    \n",
    "def sequential_similarities(data, similarity_function=score_cosine):\n",
    "    print(\"calculating sequential similarity...\")\n",
    "    similarities = [1] + [similarity_function(data[i], data[i+1]) for i in range(0, len(data)-1)]\n",
    "    return similarities\n",
    "\n",
    "def similarities(data, similarity_function=score_cosine):\n",
    "    print(\"calculating all similarities...\")\n",
    "    similarities = []\n",
    "    for x in data:       \n",
    "        similarities.append([similarity_function(x, y) for y in data])\n",
    "    return similarities\n",
    "\n",
    "def most_similar_samples(sample, sample_similarities, n=5):\n",
    "    print('Finding most similar samples for', sample + '...')\n",
    "    s = sample_similarities[s2i[sample]]\n",
    "    best = reversed(np.argsort(s)[-n:])\n",
    "    return [i2s[b] for b in best]\n",
    "\n",
    "def threshold_operons_sequential(similarities, threshold=0.6):\n",
    "    '''threshold a sequential list of similarities. \n",
    "    This means the spatial location of the genes is used\n",
    "    '''\n",
    "    cluster = 0\n",
    "    threshold_operons = defaultdict(list)\n",
    "    print('thresholding similarity into operons...')\n",
    "    for i, sim in enumerate(similarities):\n",
    "        if i == 0:\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "            continue\n",
    "        if sim > threshold:\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "        else:\n",
    "            cluster += 1\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "    labels = [label for label, operon in threshold_operons.items() for _ in operon]\n",
    "    return labels, threshold_operons\n",
    "\n",
    "def read_gold_operons(path):\n",
    "    operons_per_id = defaultdict(list)\n",
    "    with open(path, 'r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        header = next(reader)\n",
    "        for line in reader:\n",
    "            operon_id = line[0]\n",
    "            gene_id = line[2]\n",
    "            operons_per_id[operon_id].append(gene_id)\n",
    "    labels_dict = {gene:label for label, operon in enumerate(operons_per_id.values()) for gene in operon}\n",
    "    gold_labels = [labels_dict[gene] for gene in i2g]\n",
    "    gold_dict = {gene:operon for operon in operons_per_id.values() for gene in operon}\n",
    "    return gold_labels, gold_dict\n",
    "\n",
    "def validate_operon(gene, predicted_operon, gold_dict):\n",
    "    '''\n",
    "    Validates the operon (set) of a gene (id string)\n",
    "    on recall and precision of the operon members\n",
    "    using the gold standard operon dict\n",
    "    '''\n",
    "    gold_operon = set(gold_dict[gene])\n",
    "    recall = len(gold_operon.intersection(predicted_operon))/len(gold_operon)\n",
    "    precision = len(gold_operon.intersection(predicted_operon))/len(predicted_operon)\n",
    "    is_correct = int(set(predicted_operon) == gold_operon)\n",
    "    return recall, precision, is_correct\n",
    "\n",
    "def validate_operons(predicted_dict, gold_dict):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    correct = []\n",
    "    print('validating predicted operons...')\n",
    "    for operon in predicted_dict.values():\n",
    "        for gene in operon:\n",
    "            score = validate_operon(gene, operon, gold_dict)\n",
    "            recall_scores.append(score[0])\n",
    "            precision_scores.append(score[1])\n",
    "            correct.append(score[2])\n",
    "    results = {}\n",
    "    results['recall'] = np.mean(recall_scores)\n",
    "    results['precision'] = np.mean(precision_scores)\n",
    "    results['f1'] = 2*(results['precision']*results['recall'])/(results['precision']+results['recall'])\n",
    "    results['accuracy'] = np.sum(correct)/len(correct)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "from sklearn.model_selection import KFold\n",
    "                     \n",
    "def is_operon_pair(gold_labels, gene1, gene2):\n",
    "    return(int(gold_labels[gene1] == gold_labels[gene2]))\n",
    "\n",
    "def select_features(X, y, f=50):\n",
    "    k = SelectKBest(f_regression, k=f).fit(X, y)\n",
    "    choose = k.get_support()\n",
    "    chosen_features = [i2s[i] for i in range(0, len(choose)) if choose[i]]\n",
    "    return k.transform(X), chosen_features\n",
    "\n",
    "def k_fold(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(X[train_index], y[train_index])\n",
    "        predictions = logreg.predict(X[test_index])\n",
    "        correct = np.sum([1 for i, p in enumerate(predictions) if p==y[test_index][i]])\n",
    "        accuracy = correct/len(y[test_index])\n",
    "        results.append(accuracy)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_samples('GSE67023', download=False)\n",
    "offset = 2\n",
    "df = pd.read_csv('data/eichenberger_full_matrix.csv').fillna(0)\n",
    "gold_gene_names = json.load(open('data/gold_gene_names.json'))\n",
    "df = df[df['gene'].isin(set(gold_gene_names))]\n",
    "gene_data = df.values[:, offset:].astype(float)\n",
    "sample_data = df.values[:, offset:].astype(float).transpose()\n",
    "\n",
    "i2s = list(df)[offset:] # index to sample name\n",
    "s2i = {sample: i for i, sample in enumerate(i2s)} # sample name to index\n",
    "\n",
    "i2g = df.values[:, 1] # index to gene name\n",
    "g2i = {gene: i for i, gene in enumerate(i2g)} # gene name to index\n",
    "\n",
    "gold_labels, gold_dict = read_gold_operons('data/1240.opr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rand index and p/r/f1 as score for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating sequential similarity...\n",
      "calculating all similarities...\n",
      "Finding most similar samples for Com2_T-1.5...\n",
      "['Com2_T-1.5', 'Com2_T-1.0', 'Com1_T+2.5', 'ComK2_T2.5', 'ComK2_T1.5']\n",
      "\n",
      "thresholding similarity into operons...\n",
      "The adjusted Rand score of the benchmark is: 0.0\n",
      "The adjusted Rand score of the predicted operons is: 0.7016422789112293\n",
      "\n",
      "validating predicted operons...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'true_operon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1e1999073ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_operons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The mean recall of the benchmark is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The mean precision of the benchmark is:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7a0c125e641b>\u001b[0m in \u001b[0;36mvalidate_operons\u001b[0;34m(predicted_dict, gold_dict)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moperon\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicted_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_operon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgold_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mrecall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprecision_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-7a0c125e641b>\u001b[0m in \u001b[0;36mvalidate_operon\u001b[0;34m(gene, predicted_operon, gold_dict)\u001b[0m\n\u001b[1;32m     75\u001b[0m     '''\n\u001b[1;32m     76\u001b[0m     \u001b[0mgold_operon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_operon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_operon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_operon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_operon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_operon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_operon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mis_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_operon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgold_operon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_operon' is not defined"
     ]
    }
   ],
   "source": [
    "## Similarities\n",
    "sequential_gene_similarities_cosine = sequential_similarities(gene_data)\n",
    "sample_similarities_cosine = similarities(sample_data)\n",
    "\n",
    "## Similar samples\n",
    "random_sample = i2s[random.randint(0, len(i2s))]\n",
    "print(most_similar_samples(random_sample, sample_similarities_cosine))\n",
    "print()\n",
    "\n",
    "## Predictions\n",
    "benchmark_labels = [i for i, gene in enumerate(i2g)]\n",
    "benchmark_dict = {gene:[gene] for gene in i2g}\n",
    "predicted_labels, predicted_dict = threshold_operons_sequential(\n",
    "    sequential_gene_similarities_cosine, threshold=0.6)\n",
    "\n",
    "## Validation\n",
    "print('The adjusted Rand score of the benchmark is:',\n",
    "      adjusted_rand_score(gold_labels, benchmark_labels))\n",
    "\n",
    "print('The adjusted Rand score of the predicted operons is:',\n",
    "      adjusted_rand_score(gold_labels, predicted_labels))\n",
    "print()\n",
    "\n",
    "results = validate_operons(benchmark_dict, gold_dict)\n",
    "print(\"The mean recall of the benchmark is:\", results['recall'])\n",
    "print(\"The mean precision of the benchmark is:\", results['precision'])\n",
    "print(\"The f1 of the benchmark is:\", results['f1'])\n",
    "print(\"The accuracy of the benchmark is:\", results['accuracy'])\n",
    "print()\n",
    "\n",
    "\n",
    "results = validate_operons(predicted_dict, gold_dict)\n",
    "print(\"The mean recall of the predicted operons is:\", results['recall'])\n",
    "print(\"The mean precision of the predicted operons is:\", results['precision'])\n",
    "print(\"The f1 of the predicted operons is:\", results['f1'])\n",
    "print(\"The accuracy of the predicted operons is:\", results['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "\n",
    "sequential_target_names = [i2g[i]+'-'+i2g[i+1] for i in range(0, len(i2g)-2)]\n",
    "sequential_target_values = np.array([is_operon_pair(gold_labels, i, i+1) \n",
    "                                     for i in range(0, len(gene_data)-2)])\n",
    "sequential_data = np.array([np.square(gene_data[i]-gene_data[i+1]) \n",
    "                            for i in range(0, len(gene_data)-2)])\n",
    "X, features = select_features(sequential_data, sequential_target_values, f=20)\n",
    "print(\"The best sample conditions for finding operons are:\", features)\n",
    "results_all = k_fold(sequential_data, sequential_target_values, k=10)\n",
    "results_selected = k_fold(X, sequential_target_values, k=10)\n",
    "print(\"mean_accuracy for using all data:\", np.mean(results_all))\n",
    "print(\"results for selected data:\", np.mean(results_selected))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
