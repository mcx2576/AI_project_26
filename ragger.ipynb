{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "\n",
    "def download_experiment(experiment):\n",
    "    GEOparse.get_GEO(geo=experiment, destdir=\"data/\")\n",
    "\n",
    "def read_experiment(experiment):\n",
    "    return GEOparse.get_GEO(filepath=\"data/\" + experiment + \"_family.soft.gz\")\n",
    "\n",
    "def aggregate_samples(experiment):\n",
    "    # download_experiment(experiment)\n",
    "    print('reading experiment...')\n",
    "    gse = read_experiment(experiment)\n",
    "    aggregated_samples = pd.DataFrame()\n",
    "    genes = pd.DataFrame()\n",
    "    print('aggregating samples...')\n",
    "    for sample in gse.gsms:\n",
    "        name = gse.gsms[sample].metadata['title'][0]\n",
    "        sample_df = gse.gsms[sample].table\n",
    "        sample_df.columns = ['gene', name]\n",
    "        genes = sample_df['gene']\n",
    "        aggregated_samples = pd.concat([aggregated_samples, sample_df[name]], axis=1)    \n",
    "    aggregated_samples = pd.concat([genes, aggregated_samples], axis=1)\n",
    "    aggregated_samples.to_csv('data/' + experiment + '_full_matrix.csv') \n",
    "    print('aggregated samples written to csv file')\n",
    "\n",
    "eichenberger = 'GSE67023'\n",
    "# aggregate_samples(eichenberger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n",
      "calculating sequential similarity...\n",
      "calculating similarities...\n",
      "Finding most similar samples for YoaUT3.5...\n",
      "['YoaUT3.5', 'YoaUT5.5', 'Rifamp1_T15', 'Gin(6825vs6827)2_T3', 'Vanco2_T0']\n",
      "thresholding similarity into operons...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print('reading data...')\n",
    "df = pd.read_csv('data/eichenberger_full_matrix.csv').fillna(0)\n",
    "gene_data = normalize(df.values[:, 2:].astype(float), axis=0, norm='l1')\n",
    "sample_data = normalize(df.values[:, 2:].astype(float), axis=0, norm='l1').transpose()\n",
    "\n",
    "i2s = list(df)[2:] # index to sample name\n",
    "s2i = {sample: i for i, sample in enumerate(i2s)} # sample name to index\n",
    "\n",
    "i2g = df.values[:, 1] # index to gene name\n",
    "g2i = {gene: i for i, gene in enumerate(i2g)} # gene name to index\n",
    "\n",
    "def distribution_parameters(gene, genes):\n",
    "    gene_differences = np.array([g-gene for g in genes])\n",
    "    covariance = np.cov(gene_differences, rowvar=False)\n",
    "    mean = np.mean(gene_differences, axis=0)\n",
    "    return mean, covariance\n",
    "\n",
    "def score_multivariate(x, mean, covariance):\n",
    "    return 1-multivariate_normal.pdf(x, mean=mean, cov=covariance)\n",
    "\n",
    "def score_cosine(x, y):\n",
    "    return (np.dot(x, np.transpose(y))/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "\n",
    "# def sample_similarities(similarity_function=gene_similarity_cosine):\n",
    "    \n",
    "def sequential_similarities(data, similarity_function=score_cosine):\n",
    "    print(\"calculating sequential similarity...\")\n",
    "    similarities = [similarity_function(data[i], data[i+1]) for i in range(0, len(data)-1)]\n",
    "    return similarities\n",
    "\n",
    "def similarities(data, similarity_function=score_cosine):\n",
    "    print(\"calculating all similarities...\")\n",
    "    similarities = []\n",
    "    for x in data:       \n",
    "        similarities.append([similarity_function(x, y) for y in data])\n",
    "    return similarities\n",
    "\n",
    "gene_similarities = sequential_similarities(gene_data)\n",
    "# multivariate_similarities = sequential_similarities[]\n",
    "sample_similarities_cosine = similarities(sample_data)\n",
    "\n",
    "def most_similar_samples(sample, sample_similarities, n=5):\n",
    "    print('Finding most similar samples for', sample + '...')\n",
    "    s = sample_similarities[s2i[sample]]\n",
    "    best = reversed(np.argsort(s)[-n:])\n",
    "    return [i2s[b] for b in best]\n",
    "\n",
    "random_sample = i2s[random.randint(0, len(i2s))]\n",
    "print(most_similar_samples(random_sample, sample_similarities_cosine))\n",
    "\n",
    "def threshold_operons_sequential(similarities, threshold=0.6):\n",
    "    '''threshold a sequential list of similarities. \n",
    "    This means the spatial location of the genes is used\n",
    "    '''\n",
    "    cluster = 0\n",
    "    threshold_operons = defaultdict(list)\n",
    "    print('thresholding similarity into operons...')\n",
    "    for i, sim in enumerate(similarities):\n",
    "        if sim > threshold:\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "        else:\n",
    "            cluster += 1\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "    print('done.')\n",
    "    return threshold_operons\n",
    "    \n",
    "operons = threshold_operons_sequential(gene_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "# AP = AffinityPropagation(damping = 0.5, max_iter = 250, affinity = 'euclidean').fit(cluster_data)\n",
    "# clusters = AP.fit_predict(cluster_data)\n",
    "Counter(clusters)\n",
    "names_per_cluster = defaultdict(list)\n",
    "for i, label in enumerate(clusters):\n",
    "    names_per_cluster[label].append(i2g[i])\n",
    "# names_per_cluster = {label: names.append(i2g[i]) for i, label in enumerate(clusters)}\n",
    "# names_per_cluster\n",
    "names_per_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validating predicted operons...\n",
      "The mean recall of the benchmark is: 0.6034474017743979\n",
      "The mean precision of the benchmark is: 1.0\n",
      "The accuracy of the benchmark is: 0.40811153358681873\n",
      "validating predicted operons...\n",
      "The mean recall of the assigned operons is: 0.7676228883072989\n",
      "The mean precision of the assigned operons is: 0.7498756569870776\n",
      "The accuracy of the assigned operons is: 0.26134347275031683\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def read_operons(path):\n",
    "    operons_per_id = defaultdict(list)\n",
    "    with open(path, 'r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        header = next(reader)\n",
    "        for line in reader:\n",
    "            operon_id = line[0]\n",
    "            gene_id = line[2]\n",
    "            operons_per_id[operon_id].append(gene_id)\n",
    "    \n",
    "    operons_per_gene = defaultdict(list)\n",
    "    for operon_list in operons_per_id.values():\n",
    "        for gene in operon_list:\n",
    "            operons_per_gene[gene] = operon_list\n",
    "    return operons_per_gene\n",
    "\n",
    "true_operons = json.load(open('data/operons.json'))\n",
    "\n",
    "def validate_operon(gene, predicted_operon):\n",
    "    '''\n",
    "    Validates the operon (set) of a gene (id string)\n",
    "    on recall and precision of the operon members\n",
    "    using the gold standard operon dict\n",
    "    '''\n",
    "    try:\n",
    "        true_operon = set(true_operons[gene])\n",
    "    except:\n",
    "#         print(\"Gene not found in gold standard set\")\n",
    "        return\n",
    "#     print(\"This gene is part of the following (true) operon:\", true_operon)\n",
    "#     print(\"The predicted operon for this gene is:\", set(predicted_operon))\n",
    "    recall = len(true_operon.intersection(predicted_operon))/len(true_operon)\n",
    "#     print(\"The recall of the predicted operon is:\", recall)\n",
    "    precision = len(true_operon.intersection(predicted_operon))/len(predicted_operon)\n",
    "#     print(\"The precision of the predicted operon is:\", precision)\n",
    "    correct = int(set(predicted_operon) == true_operon)\n",
    "    return recall, precision, correct\n",
    "       \n",
    "    \n",
    "def validate_operons(dictionary):\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    predictions = []\n",
    "    print('validating predicted operons...')\n",
    "    for cluster in dictionary.values():\n",
    "        for gene in cluster:\n",
    "            score = validate_operon(gene, cluster)\n",
    "            if score:\n",
    "                recall_scores.append(score[0])\n",
    "                precision_scores.append(score[1])\n",
    "                predictions.append(score[2])\n",
    "            else:\n",
    "                continue\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    accuracy = np.mean(predictions)\n",
    "    return mean_recall, mean_precision, accuracy\n",
    "\n",
    "benchmark = {gene: [gene] for gene in i2g}\n",
    "\n",
    "r, p, a = validate_operons(benchmark)\n",
    "print(\"The mean recall of the benchmark is:\", r)\n",
    "print(\"The mean precision of the benchmark is:\", p)\n",
    "print(\"The accuracy of the benchmark is:\", a)\n",
    "r, p, a = validate_operons(operons)\n",
    "\n",
    "print(\"The mean recall of the assigned operons is:\", r)\n",
    "print(\"The mean precision of the assigned operons is:\", p)\n",
    "print(\"The accuracy of the assigned operons is:\", a)\n",
    "\n",
    "\n",
    "# def get_operon(gene):\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
