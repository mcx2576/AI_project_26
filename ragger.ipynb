{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GEOparse\n",
    "import pandas as pd\n",
    "import csv, json\n",
    "\n",
    "def download_experiment(experiment):\n",
    "    GEOparse.get_GEO(geo=experiment, destdir=\"data/\")\n",
    "\n",
    "def process_experiment(experiment):\n",
    "    return GEOparse.get_GEO(filepath=\"data/\" + experiment + \"_family.soft.gz\")\n",
    "\n",
    "def aggregate_samples(experiment, download=True):  \n",
    "    '''\n",
    "    Wrapper function to download and process a given experiment ID,\n",
    "    aggregate the samples and write them to a csv file as a matrix.\n",
    "    '''\n",
    "    if download:\n",
    "        download_experiment(experiment)\n",
    "    print('process experiment...')\n",
    "    gse = process_experiment(experiment)\n",
    "    aggregated_samples = pd.DataFrame()\n",
    "    genes = pd.DataFrame()\n",
    "    print('aggregating samples...')\n",
    "    for sample in gse.gsms:\n",
    "        name = gse.gsms[sample].metadata['title'][0]\n",
    "        sample_df = gse.gsms[sample].table\n",
    "        sample_df.columns = ['gene', name]\n",
    "        genes = sample_df['gene']\n",
    "        aggregated_samples = pd.concat([aggregated_samples, sample_df[name]], axis=1)    \n",
    "    aggregated_samples = pd.concat([genes, aggregated_samples], axis=1)\n",
    "    aggregated_samples.to_csv('data/' + experiment + '_full_matrix.csv') \n",
    "    print('aggregated samples written to csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def distribution_parameters(gene, genes):\n",
    "    gene_differences = np.array([g-gene for g in genes])\n",
    "    covariance = np.cov(gene_differences, rowvar=False)\n",
    "    mean = np.mean(gene_differences, axis=0)\n",
    "    return mean, covariance\n",
    "\n",
    "def score_multivariate(x, mean, covariance):\n",
    "    return 1-multivariate_normal.pdf(x, mean=mean, cov=covariance)\n",
    "\n",
    "def score_cosine(x, y):\n",
    "    return (np.dot(x, np.transpose(y))/(np.linalg.norm(x)*np.linalg.norm(y)))\n",
    "    \n",
    "def sequential_similarities(data, similarity_function=score_cosine):\n",
    "    print(\"calculating sequential similarity...\")\n",
    "    similarities = [1] + [similarity_function(data[i], data[i+1]) for i in range(0, len(data)-1)]\n",
    "    return similarities\n",
    "\n",
    "def similarities(data, similarity_function=score_cosine):\n",
    "    print(\"calculating all similarities...\")\n",
    "    similarities = []\n",
    "    for x in data:       \n",
    "        similarities.append([similarity_function(x, y) for y in data])\n",
    "    return similarities\n",
    "\n",
    "def most_similar_samples(sample, sample_similarities, n=5):\n",
    "    print('Finding most similar samples for', sample + '...')\n",
    "    s = sample_similarities[s2i[sample]]\n",
    "    best = reversed(np.argsort(s)[-n:])\n",
    "    return [i2s[b] for b in best]\n",
    "\n",
    "def threshold_operons_sequential(similarities, threshold=0.6):\n",
    "    '''threshold a sequential list of similarities. \n",
    "    This means the spatial location of the genes is used\n",
    "    '''\n",
    "    cluster = 0\n",
    "    threshold_operons = defaultdict(list)\n",
    "    print('thresholding similarity into operons...')\n",
    "    for i, sim in enumerate(similarities):\n",
    "        if i == 0:\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "            continue\n",
    "        if sim > threshold:\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "        else:\n",
    "            cluster += 1\n",
    "            threshold_operons[cluster].append(i2g[i])\n",
    "    labels = [label for label, operon in threshold_operons.items() for _ in operon]\n",
    "    print('done.')\n",
    "    return labels\n",
    "\n",
    "def read_gold_operons(path):\n",
    "    operons_per_id = defaultdict(list)\n",
    "    with open(path, 'r') as infile:\n",
    "        reader = csv.reader(infile, delimiter='\\t')\n",
    "        header = next(reader)\n",
    "        for line in reader:\n",
    "            operon_id = line[0]\n",
    "            gene_id = line[2]\n",
    "            operons_per_id[operon_id].append(gene_id)\n",
    "    labels_dict = {gene:label for label, operon in enumerate(operons_per_id.values()) for gene in operon}\n",
    "    labels_ordered = [labels_dict[gene] for gene in i2g]\n",
    "    return labels_ordered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "from sklearn.model_selection import KFold\n",
    "                     \n",
    "def is_operon_pair(gold_labels, gene1, gene2):\n",
    "    return(int(gold_labels[gene1] == gold_labels[gene2]))\n",
    "\n",
    "def select_features(X, y, f=50):\n",
    "    k = SelectKBest(f_regression, k=f).fit(X, y)\n",
    "    choose = k.get_support()\n",
    "    chosen_features = [i2s[i] for i in range(0, len(choose)) if choose[i]]\n",
    "    return k.transform(X), chosen_features\n",
    "\n",
    "def k_fold(X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    results = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        logreg = LogisticRegression()\n",
    "        logreg.fit(X[train_index], y[train_index])\n",
    "        predictions = logreg.predict(X[test_index])\n",
    "        correct = np.sum([1 for i, p in enumerate(predictions) if p==y[test_index][i]])\n",
    "        accuracy = correct/len(y[test_index])\n",
    "        results.append(accuracy)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_samples('GSE67023', download=False)\n",
    "offset = 2\n",
    "df = pd.read_csv('data/eichenberger_full_matrix.csv').fillna(0)\n",
    "gold_gene_names = json.load(open('data/gold_gene_names.json'))\n",
    "df = df[df['gene'].isin(set(gold_gene_names))]\n",
    "gene_data = df.values[:, offset:].astype(float)\n",
    "sample_data = df.values[:, offset:].astype(float).transpose()\n",
    "\n",
    "i2s = list(df)[offset:] # index to sample name\n",
    "s2i = {sample: i for i, sample in enumerate(i2s)} # sample name to index\n",
    "\n",
    "i2g = df.values[:, 1] # index to gene name\n",
    "g2i = {gene: i for i, gene in enumerate(i2g)} # gene name to index\n",
    "\n",
    "gold_operons = read_gold_operons('data/1240.opr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rand index for similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating sequential similarity...\n",
      "calculating all similarities...\n",
      "Finding most similar samples for Germ1_T90min...\n",
      "['Germ1_T90min', 'Com1_T+0.5', 'Vanco1_T15', 'SigMT30_2', 'RemA1_T30']\n",
      "thresholding similarity into operons...\n",
      "done.\n",
      "The adjusted Rand score of the benchmark is: 0.0\n",
      "The adjusted Rand score of the predicted operons is: 0.7016422789112293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## Similarities\n",
    "sequential_gene_similarities_cosine = sequential_similarities(gene_data)\n",
    "sample_similarities_cosine = similarities(sample_data)\n",
    "\n",
    "## Similar samples\n",
    "random_sample = i2s[random.randint(0, len(i2s))]\n",
    "print(most_similar_samples(random_sample, sample_similarities_cosine))\n",
    "\n",
    "## Predictions\n",
    "benchmark_operons = [i for i, gene in enumerate(i2g)]\n",
    "predicted_operons = threshold_operons_sequential(sequential_gene_similarities_cosine)\n",
    "\n",
    "## Validation\n",
    "print('The adjusted Rand score of the benchmark is:',\n",
    "      adjusted_rand_score(gold_operons, benchmark_operons))\n",
    "\n",
    "print('The adjusted Rand score of the predicted operons is:',\n",
    "      adjusted_rand_score(gold_operons, predicted_operons))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import json\n",
    "\n",
    "sequential_target_names = [i2g[i]+'-'+i2g[i+1] for i in range(0, len(i2g)-2)]\n",
    "sequential_target_values = np.array([is_operon_pair(gold_operons, i, i+1) \n",
    "                                     for i in range(0, len(gene_data)-2)])\n",
    "sequential_data = np.array([np.square(gene_data[i]-gene_data[i+1]) \n",
    "                            for i in range(0, len(gene_data)-2)])\n",
    "X, features = select_features(sequential_data, sequential_target_values, f=50)\n",
    "results_all = k_fold(sequential_data, sequential_target_values, k=10)\n",
    "results_selected = k_fold(X, sequential_target_values, k=10)\n",
    "print(\"mean_accuracy for using all data:\", np.mean(results_all))\n",
    "print(\"results for selected data:\", np.mean(results_selected))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
